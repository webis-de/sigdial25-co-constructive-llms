{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df1cc9eb-6b6a-4cd2-aa5a-ec169ff2a4ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.colors as mcolors\n",
    "sns.set_theme(style=\"whitegrid\")#, palette=\"colorblind\")\n",
    "tol_colors = [\n",
    "    \"#88CCEE\", \"#332288\", \"#44AA99\", \"#117733\", \"#999933\",\n",
    "    \"#DDCC77\", \"#CC6677\", \"#882255\", \"#AA4499\", \"#DDDDDD\"]\n",
    "alpha_value = 0.8  # Adjust transparency here\n",
    "tol_colors = [(mcolors.to_rgba(c, alpha=alpha_value)) for c in tol_colors]\n",
    "#sns.set_palette(tol_colors)\n",
    "import numpy as np\n",
    "import ast\n",
    "from scipy.stats import skewtest, mannwhitneyu, fisher_exact, wilcoxon\n",
    "import numpy as np\n",
    "from scipy.stats import kendalltau\n",
    "import json\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3196d46-9ed1-4a49-8831-41f2b45cc327",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dlg_act_label': ['(D01) To ask a check question',\n",
       "  '(D02) To ask what/how question',\n",
       "  '(D03) To ask other kind of questions',\n",
       "  '(D04) To answer a question by confirming',\n",
       "  '(D05) To answer a question by disconfirming',\n",
       "  '(D06) Answer - Other',\n",
       "  '(D07) Agreement',\n",
       "  '(D08) Disagreement',\n",
       "  '(D09) Other',\n",
       "  '(D10) To provide informing statement'],\n",
       " 'exp_act_label': ['(E01) Testing understanding',\n",
       "  '(E02) Testing prior knowledge',\n",
       "  '(E03) Provide an explanation',\n",
       "  '(E04) Ask for an explanation',\n",
       "  '(E05) Signaling understanding',\n",
       "  '(E06) Signaling non-understanding',\n",
       "  '(E07) Providing Feedback',\n",
       "  '(E08) Providing Assessment',\n",
       "  '(E09) Introducing Extraneous Information',\n",
       "  '(E10) Other']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turn_labels = {}\n",
    "eli5_df = pd.read_pickle(\"eli5_ds/annotation-results/MACE-measure/final_mace_predictions.pkl\")\n",
    "\n",
    "eli5_df['exp_act_label'] = eli5_df.exp_act_label.apply(lambda x: '(E10) Other' if x == '(E09) Other' else x)\n",
    "eli5_df['exp_act_label'] = eli5_df.exp_act_label.apply(lambda x: '(E09) Introducing Extraneous Information' if x == '(E10) Introducing Extraneous Information' else x)\n",
    "\n",
    "eli5_df['dlg_act_label'] = eli5_df.dlg_act_label.apply(lambda x: '(D09) Other' if x == '(D10) Other' else x)\n",
    "eli5_df['dlg_act_label'] = eli5_df.dlg_act_label.apply(lambda x: '(D10) To provide informing statement' if x == '(D09) To provide informing statement' else x)\n",
    "\n",
    "eli5_df['dlg_act_label'] = eli5_df.dlg_act_label.apply(lambda x: '(D06) Answer - Other' if x == '(D06) To answer - Other' else x)\n",
    "eli5_df['dlg_act_label'] = eli5_df.dlg_act_label.apply(lambda x: '(D07) Agreement' if x == '(D07) To provide agreement statement' else x)\n",
    "eli5_df['dlg_act_label'] = eli5_df.dlg_act_label.apply(lambda x: '(D08) Disagreement' if x == '(D08) To provide disagreement statement' else x)\n",
    "\n",
    "turn_labels[\"dlg_act_label\"] = sorted(list(eli5_df.dlg_act_label.unique()))\n",
    "turn_labels[\"exp_act_label\"] = sorted(list(eli5_df.exp_act_label.unique()))\n",
    "#turn_labels[\"topic_func_label\"] = sorted(list(eli5_df.topic_func_label.unique()))\n",
    "turn_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77d628a4-7a7c-487e-9631-526b5334d715",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"final_mace_predictions_longformer-base-4096.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6343532-b199-42b7-b297-398c57727877",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>turn_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>system_prompt</th>\n",
       "      <th>turn_text</th>\n",
       "      <th>turn_text_with_topic</th>\n",
       "      <th>dlg_act_label_predictions</th>\n",
       "      <th>exp_act_label_predictions</th>\n",
       "      <th>topic_func_label_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31479367-972d-4be0-a5b7-b545b8667bd1</td>\n",
       "      <td>0</td>\n",
       "      <td>The board game Quarto and its rules</td>\n",
       "      <td>base</td>\n",
       "      <td>{'author': 'Explanee', 'text': 'Hello'}</td>\n",
       "      <td>{'author': 'Explanee', 'text': 'The board game...</td>\n",
       "      <td>(D09) Other</td>\n",
       "      <td>(E10) Other</td>\n",
       "      <td>(T04) Other - No topic was introduced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31479367-972d-4be0-a5b7-b545b8667bd1</td>\n",
       "      <td>1</td>\n",
       "      <td>The board game Quarto and its rules</td>\n",
       "      <td>base</td>\n",
       "      <td>{'author': 'Explainer', 'text': 'Hello. Welcom...</td>\n",
       "      <td>{'author': 'Explainer', 'text': 'The board gam...</td>\n",
       "      <td>(D02) To ask what/how question</td>\n",
       "      <td>(E02) Testing prior knowledge</td>\n",
       "      <td>(T04) Other - No topic was introduced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31479367-972d-4be0-a5b7-b545b8667bd1</td>\n",
       "      <td>2</td>\n",
       "      <td>The board game Quarto and its rules</td>\n",
       "      <td>base</td>\n",
       "      <td>{'author': 'Explanee', 'text': 'I would like t...</td>\n",
       "      <td>{'author': 'Explanee', 'text': 'The board game...</td>\n",
       "      <td>(D06) Answer - Other</td>\n",
       "      <td>(E03) Provide an explanation</td>\n",
       "      <td>(T01) It is the main topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31479367-972d-4be0-a5b7-b545b8667bd1</td>\n",
       "      <td>3</td>\n",
       "      <td>The board game Quarto and its rules</td>\n",
       "      <td>base</td>\n",
       "      <td>{'author': 'Explainer', 'text': 'Quatro is a s...</td>\n",
       "      <td>{'author': 'Explainer', 'text': 'The board gam...</td>\n",
       "      <td>(D06) Answer - Other</td>\n",
       "      <td>(E03) Provide an explanation</td>\n",
       "      <td>(T01) It is the main topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31479367-972d-4be0-a5b7-b545b8667bd1</td>\n",
       "      <td>4</td>\n",
       "      <td>The board game Quarto and its rules</td>\n",
       "      <td>base</td>\n",
       "      <td>{'author': 'Explanee', 'text': 'Explain all th...</td>\n",
       "      <td>{'author': 'Explanee', 'text': 'The board game...</td>\n",
       "      <td>(D06) Answer - Other</td>\n",
       "      <td>(E03) Provide an explanation</td>\n",
       "      <td>(T01) It is the main topic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                task_id  turn_id  \\\n",
       "0  31479367-972d-4be0-a5b7-b545b8667bd1        0   \n",
       "1  31479367-972d-4be0-a5b7-b545b8667bd1        1   \n",
       "2  31479367-972d-4be0-a5b7-b545b8667bd1        2   \n",
       "3  31479367-972d-4be0-a5b7-b545b8667bd1        3   \n",
       "4  31479367-972d-4be0-a5b7-b545b8667bd1        4   \n",
       "\n",
       "                                 topic system_prompt  \\\n",
       "0  The board game Quarto and its rules          base   \n",
       "1  The board game Quarto and its rules          base   \n",
       "2  The board game Quarto and its rules          base   \n",
       "3  The board game Quarto and its rules          base   \n",
       "4  The board game Quarto and its rules          base   \n",
       "\n",
       "                                           turn_text  \\\n",
       "0            {'author': 'Explanee', 'text': 'Hello'}   \n",
       "1  {'author': 'Explainer', 'text': 'Hello. Welcom...   \n",
       "2  {'author': 'Explanee', 'text': 'I would like t...   \n",
       "3  {'author': 'Explainer', 'text': 'Quatro is a s...   \n",
       "4  {'author': 'Explanee', 'text': 'Explain all th...   \n",
       "\n",
       "                                turn_text_with_topic  \\\n",
       "0  {'author': 'Explanee', 'text': 'The board game...   \n",
       "1  {'author': 'Explainer', 'text': 'The board gam...   \n",
       "2  {'author': 'Explanee', 'text': 'The board game...   \n",
       "3  {'author': 'Explainer', 'text': 'The board gam...   \n",
       "4  {'author': 'Explanee', 'text': 'The board game...   \n",
       "\n",
       "        dlg_act_label_predictions      exp_act_label_predictions  \\\n",
       "0                     (D09) Other                    (E10) Other   \n",
       "1  (D02) To ask what/how question  (E02) Testing prior knowledge   \n",
       "2            (D06) Answer - Other   (E03) Provide an explanation   \n",
       "3            (D06) Answer - Other   (E03) Provide an explanation   \n",
       "4            (D06) Answer - Other   (E03) Provide an explanation   \n",
       "\n",
       "            topic_func_label_predictions  \n",
       "0  (T04) Other - No topic was introduced  \n",
       "1  (T04) Other - No topic was introduced  \n",
       "2             (T01) It is the main topic  \n",
       "3             (T01) It is the main topic  \n",
       "4             (T01) It is the main topic  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a625ece6-5af7-41cf-b483-e07897114656",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"final_mace_predictions_longformer-base-4096.pkl\")\n",
    "turn_counts = {}\n",
    "for author in [\"Explanee\", \"Explainer\"]:\n",
    "    turn_counts[author] = {}\n",
    "    for system_prompt in [\"base\", \"enhanced\"]:\n",
    "        turn_counts[author][system_prompt] = {}\n",
    "        for turn_label in turn_labels:\n",
    "            \n",
    "            turn_counts[author][system_prompt][turn_label] = {}\n",
    "            df.apply(lambda row: row['turn_text']['author'], axis=1)\n",
    "            # Filter dataframe\n",
    "            filtered_df = df[\n",
    "                (df[\"system_prompt\"] == system_prompt) &\n",
    "                (df[\"turn_text\"].map(lambda x: x[\"author\"] == author))\n",
    "            ]\n",
    "            \n",
    "            grouped_counts = (\n",
    "                filtered_df.groupby(\"task_id\")[turn_label + \"_predictions\"]\n",
    "                .value_counts()\n",
    "                .unstack(fill_value=0)  # Ensure all categories appear, filling missing ones with zero\n",
    "                .stack()\n",
    "            )\n",
    "            \n",
    "            num_queries = grouped_counts.groupby('task_id').sum(numeric_only=True).to_dict()\n",
    "            \n",
    "            grouped_counts = grouped_counts.to_dict()\n",
    "            \n",
    "            for (task_id, turn), value in grouped_counts.items():\n",
    "                if turn not in turn_counts[author][system_prompt][turn_label]:\n",
    "                    turn_counts[author][system_prompt][turn_label][turn] = []\n",
    "                turn_counts[author][system_prompt][turn_label][turn].append(value/num_queries[task_id])\n",
    "\n",
    "p_values = {}\n",
    "for author in [\"Explanee\", \"Explainer\"]:\n",
    "    p_values[author] = {}\n",
    "    for turn_label in turn_labels:\n",
    "        p_values[author][turn_label] = {}\n",
    "        for turn in turn_labels[turn_label]:\n",
    "            if turn in turn_counts[author][\"base\"][turn_label] and turn in turn_counts[author][\"enhanced\"][turn_label]:\n",
    "                data_base = turn_counts[author][\"base\"][turn_label][turn]\n",
    "                data_enhanced = turn_counts[author][\"enhanced\"][turn_label][turn]\n",
    "                statistic, p_value = mannwhitneyu(data_base, data_enhanced)\n",
    "                p_values[author][turn_label][turn] = p_value\n",
    "\n",
    "with open(\"p_values_turn_counts.json\", \"w\") as file:\n",
    "    json.dump(p_values, file, indent=4)\n",
    "                \n",
    "for author in [\"Explanee\", \"Explainer\"]:\n",
    "    for system_prompt in [\"base\", \"enhanced\"]:\n",
    "        for turn_label in turn_labels:\n",
    "            for turn in turn_labels[turn_label]:\n",
    "                if turn not in turn_counts[author][system_prompt][turn_label]:\n",
    "                    turn_counts[author][system_prompt][turn_label][turn] = 0\n",
    "                else:\n",
    "                    values_mean = np.mean(turn_counts[author][system_prompt][turn_label][turn])\n",
    "                    values_std = np.std(turn_counts[author][system_prompt][turn_label][turn])\n",
    "                    turn_counts[author][system_prompt][turn_label][turn] = values_mean\n",
    "\n",
    "for author in [\"Explanee\", \"Explainer\"]:\n",
    "    data = []\n",
    "\n",
    "    for turn_label in turn_labels:\n",
    "        rest_values = {\"base\": 0, \"enhanced\": 0}\n",
    "        \n",
    "        values_base_sum = sum(list(turn_counts[author][\"base\"][turn_label].values()))\n",
    "        values_enhanced_sum = sum(list(turn_counts[author][\"enhanced\"][turn_label].values()))\n",
    "\n",
    "        for turn in turn_counts[author][\"base\"][turn_label]:\n",
    "            value_base = turn_counts[author][\"base\"][turn_label][turn] / values_base_sum\n",
    "            value_enhanced = turn_counts[author][\"enhanced\"][turn_label][turn] / values_enhanced_sum\n",
    "            if author == \"Explanee\":\n",
    "                threshold = 0.05\n",
    "            else:\n",
    "                threshold = 0.02\n",
    "            if (value_base < threshold and value_enhanced < threshold) or \"Other\" in turn:\n",
    "                rest_values[\"base\"] += value_base\n",
    "                rest_values[\"enhanced\"] += value_enhanced\n",
    "            else:\n",
    "                data.append({\n",
    "                    \"Category\": turn, \n",
    "                    \"Proportion\": value_base, \n",
    "                    \"Type\": \"base\", \n",
    "                    \"Label\": turn_label\n",
    "                })\n",
    "                data.append({\n",
    "                    \"Category\": turn, \n",
    "                    \"Proportion\": value_enhanced, \n",
    "                    \"Type\": \"enhanced\", \n",
    "                    \"Label\": turn_label\n",
    "                })\n",
    "\n",
    "        for system_prompt in rest_values:\n",
    "            data.append({\n",
    "                \"Category\": \"Rest\", \n",
    "                \"Proportion\": rest_values[system_prompt], \n",
    "                \"Type\": system_prompt, \n",
    "                \"Label\": turn_label\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Create subplots for each turn_label within the same figure\n",
    "    fig, axes = plt.subplots(1, len(turn_labels), figsize=(7.5, 4.2), sharey=True)\n",
    "    turn_label_dict = {\"dlg_act_label\": \"Dialogue Acts\", \"exp_act_label\": \"Explanation Moves\"}\n",
    "\n",
    "    for i, turn_label in enumerate(turn_labels):\n",
    "        ax = axes[i]\n",
    "        df_subset = df[df[\"Label\"] == turn_label].copy()\n",
    "        df_pivot = df_subset.pivot(index=\"Type\", columns=\"Category\", values=\"Proportion\")\n",
    "        df_pivot = df_pivot.fillna(0)\n",
    "\n",
    "        total_categories = df_pivot.columns\n",
    "\n",
    "        df_pivot = df_pivot[df_pivot.columns[::-1]]\n",
    "        \n",
    "        df_pivot.plot(\n",
    "            kind=\"bar\", \n",
    "            stacked=True, \n",
    "            ax=ax, \n",
    "            color=tol_colors[-1:] + tol_colors[:len(total_categories)-1]\n",
    "        )\n",
    "\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_title(turn_label_dict[turn_label], fontsize=9)\n",
    "        ax.set_ylim(0, 1.0)\n",
    "        ax.set_yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "        ax.yaxis.tick_right()\n",
    "        ax.set_yticklabels([\"0%\", \"10%\", \"20%\", \"30%\", \"40%\", \"50%\", \"60%\", \"70%\", \"80%\", \"90%\", \"100%\"], fontsize=9)\n",
    "        for label in ax.get_yticklabels():\n",
    "            label.set_horizontalalignment('center')\n",
    "        ax.tick_params(axis='y', length=0)\n",
    "        ax.set_xticks([0, 1])\n",
    "        ax.set_xticklabels([\"Base\", \"Enhanced\"], fontsize=9)\n",
    "        ax.grid(False)\n",
    "        ax.legend_.remove()\n",
    "        ax.set_facecolor('none')\n",
    "\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_visible(False)\n",
    "\n",
    "        ax.tick_params(axis='x', labelrotation=0)\n",
    "            \n",
    "        # Add labels inside bars\n",
    "        for j, (setting, row) in enumerate(df_pivot.iterrows()):\n",
    "            cumulative = 0\n",
    "            for category in df_pivot.columns:\n",
    "                value = row[category]\n",
    "                if category in p_values[author][turn_label]:\n",
    "                    p_value = p_values[author][turn_label][category]\n",
    "                else:\n",
    "                    p_value = 1\n",
    "                if value >= 0.05:\n",
    "                    label = f\"{value*100:.1f}\"\n",
    "                    if p_value < 0.05:\n",
    "                        label = r\"$^\\dagger$\"+label\n",
    "                    ax.text(\n",
    "                        j, cumulative + value / 2, \n",
    "                        label, \n",
    "                        ha=\"center\", va=\"center\", fontsize=9, color=\"black\"\n",
    "                    )\n",
    "                category = category.split(\") \")[-1] \n",
    "                if i == 0 and setting == \"base\" :\n",
    "                        ax.text(\n",
    "                            j-0.3, cumulative + value/2, \n",
    "                            \"  \"+category, \n",
    "                            ha=\"right\", va=\"center\", fontsize=9, color=\"black\"\n",
    "                        )\n",
    "                elif i == 1 and setting == \"enhanced\" :\n",
    "                    ax.text(\n",
    "                        j+0.3, cumulative + value/2, \n",
    "                        category+\"  \", \n",
    "                        ha=\"left\", va=\"center\", fontsize=9, color=\"black\"\n",
    "                    )\n",
    "                    \n",
    "                cumulative += value\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.04)\n",
    "    plt.savefig(f\"turn_labels_{author}_combined.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2208520c-bc8f-4f79-afaf-2a32273cdbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../evaluation/results/results_per_user.json\", \"r\") as file:\n",
    "    stats = json.load(file)\n",
    "with open(\"../../evaluation/user_study_data/setup_per_user.json\", \"r\") as file:\n",
    "    setup_per_user = json.load(file)\n",
    "\n",
    "    \n",
    "turn_counts = {}\n",
    "p_values = {}\n",
    "df = pd.read_pickle(\"final_mace_predictions_longformer-base-4096.pkl\")\n",
    "\n",
    "for author in [\"Explanee\", \"Explainer\"]:\n",
    "    turn_counts[author] = {}\n",
    "    turn_counts[author] = {}\n",
    "    for turn_label in turn_labels:\n",
    "        turn_counts[author][turn_label] = {}\n",
    "        df.apply(lambda row: row['turn_text']['author'], axis=1)\n",
    "        # Filter dataframe\n",
    "        filtered_df = df[\n",
    "            (df[\"system_prompt\"] == \"enhanced\") &\n",
    "            (df[\"turn_text\"].map(lambda x: x[\"author\"] == author))\n",
    "        ]\n",
    "\n",
    "        grouped_counts = (\n",
    "            filtered_df.groupby(\"task_id\")[turn_label + \"_predictions\"]\n",
    "            .value_counts()\n",
    "            .unstack(fill_value=0)  # Ensure all categories appear, filling missing ones with zero\n",
    "            .stack()\n",
    "            .to_dict()\n",
    "        )\n",
    "\n",
    "        turn_counts[author][turn_label][\"obj_comprehension\"] = []\n",
    "        turn_counts[author][turn_label][\"enabledness\"] = []\n",
    "\n",
    "        old_task_id = None\n",
    "\n",
    "        for (task_id, turn), value in grouped_counts.items():\n",
    "            if turn not in turn_counts[author][turn_label]:\n",
    "                turn_counts[author][turn_label][turn] = []\n",
    "            turn_counts[author][turn_label][turn].append(value)\n",
    "            if not old_task_id or task_id !=old_task_id:\n",
    "                turn_counts[author][turn_label][\"obj_comprehension\"].append(stats[task_id][\"post_obj_comprehension\"])\n",
    "                turn_counts[author][turn_label][\"enabledness\"].append(stats[task_id][\"post_enabledness\"])\n",
    "            old_task_id = task_id\n",
    "\n",
    "SIGNIFICANCE_LEVEL = 0.05  # Set threshold for statistical significance\n",
    "for author in [\"Explanee\", \"Explainer\"]:\n",
    "    for turn_label in [\"dlg_act_label\", \"exp_act_label\"]:\n",
    "        # Extract values dynamically\n",
    "        data = np.column_stack([turn_counts[author][turn_label][metric] for metric in turn_counts[author][turn_label]])\n",
    "\n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(data, columns=turn_counts[author][turn_label])\n",
    "\n",
    "        # Compute Kendall correlation matrix\n",
    "        corr_matrix = df.corr(method=\"kendall\")\n",
    "\n",
    "        # Compute p-values\n",
    "        p_values = np.zeros(corr_matrix.shape)\n",
    "        cols = df.columns\n",
    "\n",
    "        for i in range(len(cols)):\n",
    "            for j in range(len(cols)):\n",
    "                if i != j:\n",
    "                    tau, p_value = kendalltau(df[cols[i]], df[cols[j]])\n",
    "                    p_values[i, j] = p_value\n",
    "                else:\n",
    "                    p_values[i, j] = np.nan  # No self-correlation p-value\n",
    "\n",
    "        p_values_df = pd.DataFrame(p_values, columns=cols, index=cols)\n",
    "\n",
    "        # Plot only significant correlations\n",
    "        plt.figure(figsize=(12,7))\n",
    "        ax = sns.heatmap(\n",
    "            corr_matrix,  # Show full correlation matrix\n",
    "            annot=True,\n",
    "            fmt=\".2f\",\n",
    "            linewidths=0.5,\n",
    "            cmap=\"coolwarm\",\n",
    "            vmin=-1, vmax=1\n",
    "        )\n",
    "\n",
    "        # Bold only significant correlations\n",
    "        for text, (i, j) in zip(ax.texts, [(row, col) for row in range(len(cols)) for col in range(len(cols))]):\n",
    "            if i != j and p_values_df.iloc[i, j] < SIGNIFICANCE_LEVEL:\n",
    "                text.set_weight(\"bold\")\n",
    "\n",
    "        plt.title(f\"Significant Correlations ({author}, {turn_label})\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{turn_label}_{author}_correlation_matrix.pdf', format=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99655012-32a5-416e-a415-67c0959aada3",
   "metadata": {},
   "source": [
    "### Text complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70549eb1-2a7b-4e7a-877e-c3c2df6fec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textcomplexity import surface\n",
    "from textcomplexity.utils.text import Text\n",
    "from collections import namedtuple\n",
    "import nltk\n",
    "Token = namedtuple(\"Token\", [\"word\", \"pos\"])\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3afab43-13f4-44ff-b046-3547eb7e83ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quarto 2\n",
      "Mean change in gunning fog index: +109.4\\% $\\pm$ 100.9\n",
      "Mean change in type-token-ratio: +23.0\\% $\\pm$ 2.3\n",
      "Mean change in shannon entropy: +7.1\\% $\\pm$ 8.9\n",
      "black holes 8\n",
      "Mean change in gunning fog index: --8.5\\% $\\pm$ 16.7\n",
      "Mean change in type-token-ratio: +6.0\\% $\\pm$ 43.7\n",
      "Mean change in shannon entropy: --1.6\\% $\\pm$ 5.3\n",
      "sleep 4\n",
      "Mean change in gunning fog index: --10.1\\% $\\pm$ 17.9\n",
      "Mean change in type-token-ratio: +1.9\\% $\\pm$ 12.6\n",
      "Mean change in shannon entropy: +0.8\\% $\\pm$ 7.1\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for topic in [\"Quarto\", \"black holes\", \"sleep\"]:\n",
    "    results[topic] = {}\n",
    "    df = pd.read_pickle(\"final_mace_predictions_longformer-base-4096.pkl\")\n",
    "    filtered_df = df[(df[\"turn_text\"].map(lambda x: x[\"author\"] == \"Explanee\")) & (df[\"exp_act_label_predictions\"]==\"(E06) Signaling non-understanding\")]\n",
    "\n",
    "    gunning_fog = []\n",
    "    type_token_ratio = []\n",
    "    shannon_entropy = []\n",
    "\n",
    "    for index, row in filtered_df.iterrows():\n",
    "        turn_ids = range(row[\"turn_id\"]-1, row[\"turn_id\"] + 2)\n",
    "        messages = df[\n",
    "            (df[\"task_id\"] == row[\"task_id\"]) & \n",
    "            (df[\"turn_id\"].isin(turn_ids))\n",
    "        ]\n",
    "        if len(messages) == len(turn_ids) and row[\"system_prompt\"] == \"enhanced\" and topic in row[\"topic\"] :\n",
    "            # Check that the LLM provided an explanation before the user signaled non-understanding\n",
    "            EX_provided_explanation = messages[messages['turn_id'] == row[\"turn_id\"]-1]['exp_act_label_predictions'].iloc[0] == '(E03) Provide an explanation'\n",
    "            if EX_provided_explanation:\n",
    "                current_gunning_fog = []\n",
    "                current_type_token_ratio = []\n",
    "                current_shannon_entropy = []\n",
    "                for index, message in messages.iterrows():\n",
    "                    #print(message[\"turn_text\"])\n",
    "                    #print(message[\"exp_act_label_predictions\"])\n",
    "                    #print()\n",
    "                    text_tokenized = nltk.word_tokenize(message[\"turn_text\"][\"text\"])\n",
    "                    text_tagged = nltk.pos_tag(text_tokenized)\n",
    "                    tuple_list = [] \n",
    "                    for tuple_ in text_tagged:\n",
    "                        tuple_list.append(Token(tuple_[0], tuple_[1]))\n",
    "                    tc_text = Text.from_tokens(tuple_list)\n",
    "                    gunning_fog_value = textstat.gunning_fog(message[\"turn_text\"][\"text\"])\n",
    "                    type_token_ratio_value = surface.type_token_ratio(tc_text)\n",
    "                    shannon_entropy_value = surface.entropy(tc_text)\n",
    "                    \n",
    "                    if message[\"turn_text\"][\"author\"] == \"Explainer\":\n",
    "                        current_gunning_fog.append(gunning_fog_value)\n",
    "                        current_type_token_ratio.append(type_token_ratio_value)\n",
    "                        current_shannon_entropy.append(shannon_entropy_value)\n",
    "                gunning_fog.append(current_gunning_fog)\n",
    "                type_token_ratio.append(current_type_token_ratio)\n",
    "                shannon_entropy.append(current_shannon_entropy)\n",
    "                #print(\"----------------------------------------------------------------------------------\")\n",
    "                \n",
    "\n",
    "    print(topic, len(gunning_fog))\n",
    "    if len(gunning_fog) == 0:\n",
    "        continue\n",
    "    # Convert to NumPy array\n",
    "    data_array = np.array(gunning_fog)\n",
    "    # Calculate percentage changes\n",
    "    percentage_changes = ((data_array[:, 1] - data_array[:, 0]) / data_array[:, 0]) * 100\n",
    "    # Compute mean percentage change\n",
    "    mean_percentage_change = np.mean(percentage_changes)\n",
    "    std_percentage_change = np.std(percentage_changes)\n",
    "    # Display result\n",
    "    if mean_percentage_change > 0:\n",
    "        print(f\"Mean change in gunning fog index: +{mean_percentage_change:.1f}\\\\% $\\\\pm$ {std_percentage_change:.1f}\")\n",
    "    else:\n",
    "        print(f\"Mean change in gunning fog index: -{mean_percentage_change:.1f}\\\\% $\\\\pm$ {std_percentage_change:.1f}\")\n",
    "\n",
    "    # Convert to NumPy array\n",
    "    data_array = np.array(type_token_ratio)\n",
    "    # Calculate percentage changes\n",
    "    percentage_changes = ((data_array[:, 1] - data_array[:, 0]) / data_array[:, 0]) * 100\n",
    "    # Compute mean percentage change\n",
    "    mean_percentage_change = np.mean(percentage_changes)\n",
    "    std_percentage_change = np.std(percentage_changes)\n",
    "    # Display result\n",
    "    if mean_percentage_change > 0:\n",
    "        print(f\"Mean change in type-token-ratio: +{mean_percentage_change:.1f}\\\\% $\\\\pm$ {std_percentage_change:.1f}\")\n",
    "    else:\n",
    "        print(f\"Mean change in type-token-ratio: -{mean_percentage_change:.1f}\\\\% $\\\\pm$ {std_percentage_change:.1f}\")\n",
    "\n",
    "    # Convert to NumPy array\n",
    "    data_array = np.array(shannon_entropy)\n",
    "    # Calculate percentage changes\n",
    "    percentage_changes = ((data_array[:, 1] - data_array[:, 0]) / data_array[:, 0]) * 100\n",
    "    # Compute mean percentage change\n",
    "    mean_percentage_change = np.mean(percentage_changes)\n",
    "    std_percentage_change = np.std(percentage_changes)\n",
    "    # Display result\n",
    "    if mean_percentage_change > 0:\n",
    "        print(f\"Mean change in shannon entropy: +{mean_percentage_change:.1f}\\\\% $\\\\pm$ {std_percentage_change:.1f}\")\n",
    "    else:\n",
    "        print(f\"Mean change in shannon entropy: -{mean_percentage_change:.1f}\\\\% $\\\\pm$ {std_percentage_change:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc564ded-f91c-457a-8b74-6f3050e12431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all 14\n",
      "Mean change in gunning fog index: +7.9\\% $\\pm$ 58.5\n",
      "Mean change in type-token-ratio: +7.3\\% $\\pm$ 34.4\n",
      "Mean change in shannon entropy: +0.3\\% $\\pm$ 7.1\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "gunning_fog = []\n",
    "type_token_ratio = []\n",
    "shannon_entropy = []\n",
    "    \n",
    "for topic in [\"Quarto\", \"black holes\", \"sleep\"]:\n",
    "    results[topic] = {}\n",
    "    df = pd.read_pickle(\"final_mace_predictions_longformer-base-4096.pkl\")\n",
    "    filtered_df = df[(df[\"turn_text\"].map(lambda x: x[\"author\"] == \"Explanee\")) & (df[\"exp_act_label_predictions\"]==\"(E06) Signaling non-understanding\")]\n",
    "\n",
    "    for index, row in filtered_df.iterrows():\n",
    "        turn_ids = range(row[\"turn_id\"]-1, row[\"turn_id\"] + 2)\n",
    "        messages = df[\n",
    "            (df[\"task_id\"] == row[\"task_id\"]) & \n",
    "            (df[\"turn_id\"].isin(turn_ids))\n",
    "        ]\n",
    "        if len(messages) == len(turn_ids) and row[\"system_prompt\"] == \"enhanced\" and topic in row[\"topic\"] :\n",
    "            # Check that the LLM provided an explanation before the user signaled non-understanding\n",
    "            EX_provided_explanation = messages[messages['turn_id'] == row[\"turn_id\"]-1]['exp_act_label_predictions'].iloc[0] == '(E03) Provide an explanation'\n",
    "            if EX_provided_explanation:\n",
    "                current_gunning_fog = []\n",
    "                current_type_token_ratio = []\n",
    "                current_shannon_entropy = []\n",
    "                for index, message in messages.iterrows():\n",
    "                    #print(message[\"turn_text\"])\n",
    "                    #print(message[\"exp_act_label_predictions\"])\n",
    "                    #print()\n",
    "                    text_tokenized = nltk.word_tokenize(message[\"turn_text\"][\"text\"])\n",
    "                    text_tagged = nltk.pos_tag(text_tokenized)\n",
    "                    tuple_list = [] \n",
    "                    for tuple_ in text_tagged:\n",
    "                        tuple_list.append(Token(tuple_[0], tuple_[1]))\n",
    "                    tc_text = Text.from_tokens(tuple_list)\n",
    "                    gunning_fog_value = textstat.gunning_fog(message[\"turn_text\"][\"text\"])\n",
    "                    type_token_ratio_value = surface.type_token_ratio(tc_text)\n",
    "                    shannon_entropy_value = surface.entropy(tc_text)\n",
    "                    \n",
    "                    if message[\"turn_text\"][\"author\"] == \"Explainer\":\n",
    "                        current_gunning_fog.append(gunning_fog_value)\n",
    "                        current_type_token_ratio.append(type_token_ratio_value)\n",
    "                        current_shannon_entropy.append(shannon_entropy_value)\n",
    "                gunning_fog.append(current_gunning_fog)\n",
    "                type_token_ratio.append(current_type_token_ratio)\n",
    "                shannon_entropy.append(current_shannon_entropy)\n",
    "                #print(\"----------------------------------------------------------------------------------\")\n",
    "                \n",
    "    \n",
    "print(\"all\", len(gunning_fog))\n",
    "# Convert to NumPy array\n",
    "data_array = np.array(gunning_fog)\n",
    "# Calculate percentage changes\n",
    "percentage_changes = ((data_array[:, 1] - data_array[:, 0]) / data_array[:, 0]) * 100\n",
    "# Compute mean percentage change\n",
    "mean_percentage_change = np.mean(percentage_changes)\n",
    "std_percentage_change = np.std(percentage_changes)\n",
    "# Display result\n",
    "if mean_percentage_change > 0:\n",
    "    print(f\"Mean change in gunning fog index: +{mean_percentage_change:.1f}\\\\% $\\\\pm$ {std_percentage_change:.1f}\")\n",
    "else:\n",
    "    print(f\"Mean change in gunning fog index: -{mean_percentage_change:.1f}\\\\% $\\\\pm$ {std_percentage_change:.1f}\")\n",
    "\n",
    "# Convert to NumPy array\n",
    "data_array = np.array(type_token_ratio)\n",
    "# Calculate percentage changes\n",
    "percentage_changes = ((data_array[:, 1] - data_array[:, 0]) / data_array[:, 0]) * 100\n",
    "# Compute mean percentage change\n",
    "mean_percentage_change = np.mean(percentage_changes)\n",
    "std_percentage_change = np.std(percentage_changes)\n",
    "# Display result\n",
    "if mean_percentage_change > 0:\n",
    "    print(f\"Mean change in type-token-ratio: +{mean_percentage_change:.1f}\\\\% $\\\\pm$ {std_percentage_change:.1f}\")\n",
    "else:\n",
    "    print(f\"Mean change in type-token-ratio: -{mean_percentage_change:.1f}\\\\% $\\\\pm$ {std_percentage_change:.1f}\")\n",
    "\n",
    "# Convert to NumPy array\n",
    "data_array = np.array(shannon_entropy)\n",
    "# Calculate percentage changes\n",
    "percentage_changes = ((data_array[:, 1] - data_array[:, 0]) / data_array[:, 0]) * 100\n",
    "# Compute mean percentage change\n",
    "mean_percentage_change = np.mean(percentage_changes)\n",
    "std_percentage_change = np.std(percentage_changes)\n",
    "# Display result\n",
    "if mean_percentage_change > 0:\n",
    "    print(f\"Mean change in shannon entropy: +{mean_percentage_change:.1f}\\\\% $\\\\pm$ {std_percentage_change:.1f}\")\n",
    "else:\n",
    "    print(f\"Mean change in shannon entropy: -{mean_percentage_change:.1f}\\\\% $\\\\pm$ {std_percentage_change:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdf5519",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coconstruct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
